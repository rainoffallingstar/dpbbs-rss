---
title: '量子位发表了文章: LoRA数学编程任务不敌全量微调 | 哥大&Databricks新研究'
date: '2024-05-20'
linkTitle: https://zhuanlan.zhihu.com/p/698876034
source: 量子位的知乎动态
description: <blockquote data-pid="44Z2NXea">克雷西 发自 凹非寺<br>量子位 | 公众号 QbitAI</blockquote><p
  data-pid="tp5jravy">大数据巨头Databricks与哥伦比亚大学最新研究发现，<b>在数学和编程任务上，LoRA干不过全量微调</b>。</p><p
  data-pid="931uB3Dr">具体来说，在这两种任务中，LoRA模型的精确度只有后者的八到九成左右。</p><p data-pid="qUdnneM8">不过，作者也发现，LoRA虽然学得少，但是“记忆力”却更好，<b>遗忘现象要比全量微调少</b>得多。</p><figure
  data-size="normal"><img src="https://pic1.zhimg.com/v2-2acba6083bd7b37d085581c794e4016c.jpg"
  data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="465" ...
disable_comments: true
---
<blockquote data-pid="44Z2NXea">克雷西 发自 凹非寺<br>量子位 | 公众号 QbitAI</blockquote><p data-pid="tp5jravy">大数据巨头Databricks与哥伦比亚大学最新研究发现，<b>在数学和编程任务上，LoRA干不过全量微调</b>。</p><p data-pid="931uB3Dr">具体来说，在这两种任务中，LoRA模型的精确度只有后者的八到九成左右。</p><p data-pid="qUdnneM8">不过，作者也发现，LoRA虽然学得少，但是“记忆力”却更好，<b>遗忘现象要比全量微调少</b>得多。</p><figure data-size="normal"><img src="https://pic1.zhimg.com/v2-2acba6083bd7b37d085581c794e4016c.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="465" ...