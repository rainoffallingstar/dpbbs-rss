---
title: Research Papers in February 2024
date: '2024-03-03'
linkTitle: https://sebastianraschka.com/blog/2024/research-papers-in-february-2024.html
source: Sebastian Raschka, PhD
description: Once again, this has been an exciting month in AI research. This month,
  I'm covering two new openly available LLMs, insights into small finetuned LLMs,
  and a new parameter-efficient LLM finetuning technique. The two LLMs mentioned above
  stand out for several reasons. One LLM (OLMo) is completely open source, meaning
  that everything from the training code to the dataset to the log files is openly
  shared. The other LLM (Gemma) also comes with openly available weights but achieves
  state-of-the-art performance on several benchmarks and outperforms popular LLMs
  of similar size, such as Llama 2 7B ...
disable_comments: true
---
Once again, this has been an exciting month in AI research. This month, I'm covering two new openly available LLMs, insights into small finetuned LLMs, and a new parameter-efficient LLM finetuning technique. The two LLMs mentioned above stand out for several reasons. One LLM (OLMo) is completely open source, meaning that everything from the training code to the dataset to the log files is openly shared. The other LLM (Gemma) also comes with openly available weights but achieves state-of-the-art performance on several benchmarks and outperforms popular LLMs of similar size, such as Llama 2 7B ...